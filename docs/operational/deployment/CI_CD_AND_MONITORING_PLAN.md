# æ™ºèƒ½é€šçŸ¥ç³»ç»ŸCI/CDä¸ç›‘æ§æ–¹æ¡ˆ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

åŸºäºyudao-boot-miniæ¡†æ¶çš„æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿï¼Œæ”¯æŒ10ä¸‡+ç”¨æˆ·é«˜å¹¶å‘æ¨é€ï¼Œ99.9%å¯ç”¨æ€§ç›®æ ‡ã€‚æœ¬æ–¹æ¡ˆæ¶µç›–å®Œæ•´çš„DevOpsæµç¨‹ï¼Œä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨è‡ªåŠ¨åŒ–æµç¨‹ã€‚

### æŠ€æœ¯æ ˆ
- **æ ¸å¿ƒæ¡†æ¶**: yudao-boot-mini + Spring Boot 3.4.5 + Java 21
- **å‰ç«¯**: Vue3 + Vben Admin + TypeScript
- **æ•°æ®åº“**: MySQL 8.0 + Redis 7.0
- **æ¶ˆæ¯é˜Ÿåˆ—**: Kafka 3.0 + RabbitMQ
- **å®¹å™¨åŒ–**: Docker + Kubernetes
- **CI/CD**: Jenkins + GitLab CI
- **ç›‘æ§**: Prometheus + Grafana + ELK Stack

### æ€§èƒ½ç›®æ ‡
- **æ¨é€èƒ½åŠ›**: å•æ¬¡æ¨é€10ä¸‡+ç”¨æˆ·
- **å“åº”å»¶è¿Ÿ**: æ¨é€å»¶è¿Ÿ < 5ç§’
- **ç³»ç»Ÿå¯ç”¨æ€§**: â‰¥ 99.9%
- **å¹¶å‘æ”¯æŒ**: â‰¥ 5000å¹¶å‘ç”¨æˆ·

## ğŸ³ Dockerå®¹å™¨åŒ–é…ç½®

### 1. åº”ç”¨æœåŠ¡å®¹å™¨åŒ–

#### åç«¯æœåŠ¡Dockerfileä¼˜åŒ–

```dockerfile
# ä¼˜åŒ–çš„yudao-server Dockerfile
FROM eclipse-temurin:21-jre-alpine

# åˆ›å»ºåº”ç”¨ç”¨æˆ·ï¼ˆå®‰å…¨æœ€ä½³å®è·µï¼‰
RUN addgroup -g 1001 yudao && \
    adduser -D -s /bin/sh -u 1001 -G yudao yudao

# åˆ›å»ºåº”ç”¨ç›®å½•
RUN mkdir -p /app && chown -R yudao:yudao /app
WORKDIR /app

# å¤åˆ¶jaråŒ…
COPY --chown=yudao:yudao ./target/yudao-server.jar app.jar

# è®¾ç½®æ—¶åŒºå’ŒJVMå‚æ•°
ENV TZ=Asia/Shanghai \
    JAVA_OPTS="-Xms512m -Xmx2g -XX:+UseG1GC -XX:MaxGCPauseMillis=200 \
               -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/app/dumps \
               -Djava.security.egd=file:/dev/./urandom" \
    ARGS=""

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p /app/logs /app/dumps && chown -R yudao:yudao /app

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER yudao

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:48080/actuator/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 48080

# å¯åŠ¨å‘½ä»¤
CMD ["sh", "-c", "java ${JAVA_OPTS} -jar app.jar ${ARGS}"]
```

#### å‰ç«¯Vue3å®¹å™¨åŒ–

```dockerfile
# Vue3å‰ç«¯å¤šé˜¶æ®µæ„å»º
# Stage 1: Build
FROM node:18-alpine AS builder

WORKDIR /app

# å¤åˆ¶packageæ–‡ä»¶
COPY package*.json ./
RUN npm ci --only=production

# å¤åˆ¶æºç å¹¶æ„å»º
COPY . .
RUN npm run build:prod

# Stage 2: Production
FROM nginx:1.25-alpine

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶nginxé…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# åˆ›å»ºnginxç”¨æˆ·ç›®å½•
RUN chown -R nginx:nginx /usr/share/nginx/html

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### 2. åŸºç¡€è®¾æ–½å®¹å™¨é…ç½®

#### docker-compose.prod.yml

```yaml
version: "3.8"

services:
  # MySQLä¸»åº“
  mysql-master:
    image: mysql:8.0
    container_name: mysql-master
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_REPLICATION_MODE: master
      MYSQL_REPLICATION_USER: replicator
      MYSQL_REPLICATION_PASSWORD: ${REPLICATION_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - mysql_master_data:/var/lib/mysql
      - ./conf/mysql/master.cnf:/etc/mysql/conf.d/master.cnf:ro
      - ./sql/init:/docker-entrypoint-initdb.d:ro
    command: --log-bin=mysql-bin --server-id=1
    networks:
      - backend
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10

  # MySQLä»åº“
  mysql-slave:
    image: mysql:8.0
    container_name: mysql-slave
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_REPLICATION_MODE: slave
      MYSQL_MASTER_HOST: mysql-master
      MYSQL_REPLICATION_USER: replicator
      MYSQL_REPLICATION_PASSWORD: ${REPLICATION_PASSWORD}
    ports:
      - "3307:3306"
    volumes:
      - mysql_slave_data:/var/lib/mysql
      - ./conf/mysql/slave.cnf:/etc/mysql/conf.d/slave.cnf:ro
    depends_on:
      mysql-master:
        condition: service_healthy
    command: --server-id=2
    networks:
      - backend

  # Redisé›†ç¾¤
  redis-cluster:
    image: redis:7.0-alpine
    container_name: redis-cluster
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./conf/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      timeout: 3s
      retries: 5

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - kafka_data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    networks:
      - backend

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zk_data:/var/lib/zookeeper/data
      - zk_log:/var/lib/zookeeper/log
    networks:
      - backend

  # åº”ç”¨æœåŠ¡
  notification-app:
    image: yudao/notification:${APP_VERSION}
    container_name: notification-app
    restart: unless-stopped
    ports:
      - "48080:48080"
    environment:
      SPRING_PROFILES_ACTIVE: prod
      MYSQL_MASTER_HOST: mysql-master
      MYSQL_SLAVE_HOST: mysql-slave
      REDIS_HOST: redis-cluster
      KAFKA_HOST: kafka
      JVM_OPTS: "-Xms1g -Xmx2g"
    volumes:
      - app_logs:/app/logs
      - app_dumps:/app/dumps
    depends_on:
      mysql-master:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
      kafka:
        condition: service_started
    networks:
      - backend
      - frontend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:48080/actuator/health"]
      timeout: 10s
      retries: 3
      start_period: 60s

  # å‰ç«¯æœåŠ¡
  notification-ui:
    image: yudao/notification-ui:${UI_VERSION}
    container_name: notification-ui
    restart: unless-stopped
    ports:
      - "8080:80"
    depends_on:
      - notification-app
    networks:
      - frontend

volumes:
  mysql_master_data:
  mysql_slave_data:
  redis_data:
  kafka_data:
  zk_data:
  zk_log:
  app_logs:
  app_dumps:

networks:
  backend:
    driver: bridge
  frontend:
    driver: bridge
```

## â˜¸ï¸ Kuberneteséƒ¨ç½²æ–¹æ¡ˆ

### 1. å‘½åç©ºé—´å’ŒåŸºç¡€é…ç½®

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: notification-system
  labels:
    name: notification-system
---
# èµ„æºé…é¢é™åˆ¶
apiVersion: v1
kind: ResourceQuota
metadata:
  name: notification-quota
  namespace: notification-system
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20"
    limits.memory: 40Gi
    persistentvolumeclaims: "10"
```

### 2. ConfigMapé…ç½®

```yaml
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: notification-config
  namespace: notification-system
data:
  application-prod.yaml: |
    server:
      port: 48080
      servlet:
        context-path: /api
    
    spring:
      profiles:
        active: prod
      datasource:
        dynamic:
          primary: master
          datasource:
            master:
              url: jdbc:mysql://mysql-service:3306/notification?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
              username: ${MYSQL_USERNAME}
              password: ${MYSQL_PASSWORD}
              driver-class-name: com.mysql.cj.jdbc.Driver
            slave:
              url: jdbc:mysql://mysql-slave-service:3306/notification?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
              username: ${MYSQL_USERNAME}
              password: ${MYSQL_PASSWORD}
              driver-class-name: com.mysql.cj.jdbc.Driver
      
      redis:
        host: redis-service
        port: 6379
        password: ${REDIS_PASSWORD}
        database: 0
        jedis:
          pool:
            max-active: 20
            max-idle: 10
            min-idle: 5
    
    kafka:
      bootstrap-servers: kafka-service:9092
      producer:
        retries: 3
        batch-size: 16384
        buffer-memory: 33554432
      consumer:
        group-id: notification-group
        enable-auto-commit: true
    
    yudao:
      tenant:
        enable: true
      security:
        permit-all-urls:
          - /actuator/health
          - /swagger-ui/**
          - /v3/api-docs/**
```

### 3. MySQLéƒ¨ç½²

```yaml
# mysql-deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-master
  namespace: notification-system
spec:
  serviceName: mysql-service
  replicas: 1
  selector:
    matchLabels:
      app: mysql-master
  template:
    metadata:
      labels:
        app: mysql-master
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: root-password
        - name: MYSQL_DATABASE
          value: notification
        volumeMounts:
        - name: mysql-storage
          mountPath: /var/lib/mysql
        - name: mysql-config
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          exec:
            command:
            - mysqladmin
            - ping
            - -h
            - localhost
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - mysql
            - -h
            - localhost
            - -e
            - "SELECT 1"
          initialDelaySeconds: 5
          periodSeconds: 2
      volumes:
      - name: mysql-config
        configMap:
          name: mysql-config
  volumeClaimTemplates:
  - metadata:
      name: mysql-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "fast-ssd"
      resources:
        requests:
          storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: notification-system
spec:
  selector:
    app: mysql-master
  ports:
  - port: 3306
    targetPort: 3306
  type: ClusterIP
```

### 4. Redisé›†ç¾¤éƒ¨ç½²

```yaml
# redis-deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: notification-system
spec:
  serviceName: redis-service
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7.0-alpine
        ports:
        - containerPort: 6379
        command:
        - redis-server
        - /etc/redis/redis.conf
        volumeMounts:
        - name: redis-storage
          mountPath: /data
        - name: redis-config
          mountPath: /etc/redis
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 5
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "fast-ssd"
      resources:
        requests:
          storage: 20Gi
---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: notification-system
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
  type: ClusterIP
```

### 5. åº”ç”¨æœåŠ¡éƒ¨ç½²

```yaml
# notification-app-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: notification-app
  namespace: notification-system
  labels:
    app: notification-app
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: notification-app
  template:
    metadata:
      labels:
        app: notification-app
    spec:
      containers:
      - name: notification-app
        image: yudao/notification:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 48080
          protocol: TCP
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: MYSQL_USERNAME
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: username
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: password
        volumeMounts:
        - name: app-config
          mountPath: /app/config
        - name: app-logs
          mountPath: /app/logs
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 48080
          initialDelaySeconds: 90
          periodSeconds: 15
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 48080
          initialDelaySeconds: 30
          periodSeconds: 5
      volumes:
      - name: app-config
        configMap:
          name: notification-config
      - name: app-logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: notification-service
  namespace: notification-system
spec:
  selector:
    app: notification-app
  ports:
  - name: http
    port: 80
    targetPort: 48080
  type: LoadBalancer
---
# HPAè‡ªåŠ¨æ‰©ç¼©å®¹
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: notification-app-hpa
  namespace: notification-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: notification-app
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## ğŸ”„ Jenkins CI/CDæµæ°´çº¿

### 1. Jenkinsfileæµæ°´çº¿è„šæœ¬

```groovy
// Jenkinsfile
pipeline {
    agent any
    
    parameters {
        choice(name: 'ENVIRONMENT', choices: ['dev', 'test', 'prod'], description: 'éƒ¨ç½²ç¯å¢ƒ')
        string(name: 'BRANCH', defaultValue: 'main', description: 'éƒ¨ç½²åˆ†æ”¯')
        booleanParam(name: 'SKIP_TESTS', defaultValue: false, description: 'è·³è¿‡æµ‹è¯•')
        booleanParam(name: 'FORCE_DEPLOY', defaultValue: false, description: 'å¼ºåˆ¶éƒ¨ç½²')
    }

    environment {
        // Dockeré…ç½®
        DOCKER_REGISTRY = 'harbor.company.com'
        DOCKER_NAMESPACE = 'yudao'
        IMAGE_NAME = 'notification'
        
        // Kubernetesé…ç½®
        K8S_NAMESPACE = 'notification-system'
        K8S_DEPLOYMENT = 'notification-app'
        
        // å‡­è¯ID
        DOCKER_CREDENTIAL_ID = 'harbor-credential'
        K8S_CREDENTIAL_ID = 'k8s-config'
        SONAR_CREDENTIAL_ID = 'sonarqube-token'
        
        // ç‰ˆæœ¬æ ‡ç­¾
        BUILD_VERSION = "${BUILD_NUMBER}-${GIT_COMMIT.take(8)}"
        DOCKER_TAG = "${ENVIRONMENT}-${BUILD_VERSION}"
    }

    stages {
        stage('ç¯å¢ƒåˆå§‹åŒ–') {
            steps {
                script {
                    echo "å¼€å§‹æ„å»ºç¯å¢ƒ: ${ENVIRONMENT}"
                    echo "æ„å»ºåˆ†æ”¯: ${BRANCH}"
                    echo "æ„å»ºç‰ˆæœ¬: ${BUILD_VERSION}"
                    
                    // è®¾ç½®æ„å»ºæè¿°
                    currentBuild.displayName = "#${BUILD_NUMBER}-${ENVIRONMENT}"
                    currentBuild.description = "Branch: ${BRANCH}, Env: ${ENVIRONMENT}"
                }
            }
        }

        stage('ä»£ç æ£€å‡º') {
            steps {
                checkout([
                    $class: 'GitSCM',
                    branches: [[name: "*/${BRANCH}"]],
                    userRemoteConfigs: [[url: 'https://github.com/company/notification-system.git']]
                ])
                
                script {
                    env.GIT_COMMIT = sh(returnStdout: true, script: 'git rev-parse HEAD').trim()
                    env.GIT_AUTHOR = sh(returnStdout: true, script: 'git log -1 --pretty=format:"%an"').trim()
                }
            }
        }

        stage('ä»£ç è´¨é‡æ£€æŸ¥') {
            parallel {
                stage('SonarQubeæ‰«æ') {
                    steps {
                        withSonarQubeEnv('SonarQube') {
                            sh '''
                                mvn sonar:sonar \
                                  -Dsonar.projectKey=notification-system \
                                  -Dsonar.host.url=${SONAR_HOST_URL} \
                                  -Dsonar.login=${SONAR_AUTH_TOKEN} \
                                  -Dsonar.java.coveragePlugin=jacoco \
                                  -Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml
                            '''
                        }
                    }
                }
                
                stage('å®‰å…¨æ‰«æ') {
                    steps {
                        sh '''
                            # OWASPä¾èµ–æ£€æŸ¥
                            mvn org.owasp:dependency-check-maven:check
                            
                            # è®¸å¯è¯æ£€æŸ¥
                            mvn license:check
                        '''
                    }
                }
            }
        }

        stage('è´¨é‡é—¨ç¦') {
            steps {
                timeout(time: 5, unit: 'MINUTES') {
                    waitForQualityGate abortPipeline: true
                }
            }
        }

        stage('æ„å»ºåº”ç”¨') {
            parallel {
                stage('åç«¯æ„å»º') {
                    steps {
                        sh '''
                            # Mavenæ„å»º
                            mvn clean compile -DskipTests=true
                            
                            # å¦‚æœä¸è·³è¿‡æµ‹è¯•ï¼Œæ‰§è¡Œæµ‹è¯•
                            if [ "${SKIP_TESTS}" = "false" ]; then
                                mvn test
                                mvn jacoco:report
                            fi
                            
                            # æ‰“åŒ…
                            mvn package -DskipTests=true -Pproduction
                            
                            # æ£€æŸ¥æ„å»ºäº§ç‰©
                            if [ ! -f "yudao-server/target/yudao-server.jar" ]; then
                                echo "æ„å»ºå¤±è´¥ï¼šæ‰¾ä¸åˆ°jaræ–‡ä»¶"
                                exit 1
                            fi
                        '''
                    }
                    post {
                        always {
                            // å‘å¸ƒæµ‹è¯•æŠ¥å‘Š
                            publishTestResults testResultsPattern: 'target/surefire-reports/*.xml'
                            publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')]
                        }
                    }
                }
                
                stage('å‰ç«¯æ„å»º') {
                    steps {
                        dir('yudao-ui-admin-vue3') {
                            sh '''
                                # å®‰è£…ä¾èµ–
                                npm ci
                                
                                # è¿è¡Œä»£ç æ£€æŸ¥
                                npm run lint:fix
                                npm run type-check
                                
                                # æ„å»ºç”Ÿäº§ç‰ˆæœ¬
                                npm run build:prod
                                
                                # æ£€æŸ¥æ„å»ºäº§ç‰©
                                if [ ! -d "dist" ]; then
                                    echo "å‰ç«¯æ„å»ºå¤±è´¥ï¼šæ‰¾ä¸åˆ°distç›®å½•"
                                    exit 1
                                fi
                            '''
                        }
                    }
                }
            }
        }

        stage('æ„å»ºDockeré•œåƒ') {
            parallel {
                stage('åç«¯é•œåƒ') {
                    steps {
                        script {
                            def backendImage = docker.build("${DOCKER_REGISTRY}/${DOCKER_NAMESPACE}/${IMAGE_NAME}:${DOCKER_TAG}", 
                                                           "-f yudao-server/Dockerfile yudao-server/")
                            
                            docker.withRegistry("https://${DOCKER_REGISTRY}", DOCKER_CREDENTIAL_ID) {
                                backendImage.push()
                                backendImage.push("latest")
                            }
                        }
                    }
                }
                
                stage('å‰ç«¯é•œåƒ') {
                    steps {
                        script {
                            def frontendImage = docker.build("${DOCKER_REGISTRY}/${DOCKER_NAMESPACE}/${IMAGE_NAME}-ui:${DOCKER_TAG}", 
                                                            "-f yudao-ui-admin-vue3/Dockerfile yudao-ui-admin-vue3/")
                            
                            docker.withRegistry("https://${DOCKER_REGISTRY}", DOCKER_CREDENTIAL_ID) {
                                frontendImage.push()
                                frontendImage.push("latest")
                            }
                        }
                    }
                }
            }
        }

        stage('å®‰å…¨æ‰«æé•œåƒ') {
            steps {
                script {
                    sh '''
                        # ä½¿ç”¨Trivyæ‰«æé•œåƒæ¼æ´
                        trivy image --exit-code 1 --severity HIGH,CRITICAL ${DOCKER_REGISTRY}/${DOCKER_NAMESPACE}/${IMAGE_NAME}:${DOCKER_TAG}
                    '''
                }
            }
        }

        stage('éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ') {
            when {
                expression { params.ENVIRONMENT == 'test' || params.ENVIRONMENT == 'dev' }
            }
            steps {
                script {
                    kubernetesDeploy(
                        configs: 'k8s/test/*.yaml',
                        kubeconfigId: K8S_CREDENTIAL_ID,
                        enableConfigSubstitution: true
                    )
                    
                    // ç­‰å¾…éƒ¨ç½²å®Œæˆ
                    sh """
                        kubectl rollout status deployment/${K8S_DEPLOYMENT} -n ${K8S_NAMESPACE}-${ENVIRONMENT} --timeout=300s
                    """
                }
            }
        }

        stage('é›†æˆæµ‹è¯•') {
            when {
                expression { params.ENVIRONMENT == 'test' && !params.SKIP_TESTS }
            }
            steps {
                sh '''
                    # ç­‰å¾…æœåŠ¡å°±ç»ª
                    sleep 30
                    
                    # è¿è¡Œé›†æˆæµ‹è¯•
                    mvn test -Dtest=IntegrationTest -Dspring.profiles.active=test
                    
                    # APIæµ‹è¯•
                    newman run tests/postman/notification-api-tests.json \
                           --environment tests/postman/test-environment.json \
                           --reporters cli,junit
                '''
            }
            post {
                always {
                    publishTestResults testResultsPattern: 'target/newman/*.xml'
                }
            }
        }

        stage('æ€§èƒ½æµ‹è¯•') {
            when {
                expression { params.ENVIRONMENT == 'test' && !params.SKIP_TESTS }
            }
            steps {
                sh '''
                    # JMeteræ€§èƒ½æµ‹è¯•
                    jmeter -n -t tests/jmeter/notification-load-test.jmx \
                           -l results/performance-results.jtl \
                           -j results/jmeter.log \
                           -e -o results/html-report
                '''
            }
            post {
                always {
                    publishHTML([
                        allowMissing: false,
                        alwaysLinkToLastBuild: true,
                        keepAll: true,
                        reportDir: 'results/html-report',
                        reportFiles: 'index.html',
                        reportName: 'Performance Test Report'
                    ])
                }
            }
        }

        stage('ç”Ÿäº§éƒ¨ç½²å®¡æ‰¹') {
            when {
                expression { params.ENVIRONMENT == 'prod' }
            }
            steps {
                script {
                    def approvers = ['dev-lead', 'ops-lead', 'product-manager']
                    def deployApproval = input(
                        id: 'deployApproval',
                        message: "ç¡®è®¤éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Ÿ",
                        ok: 'ç¡®è®¤éƒ¨ç½²',
                        submitterParameter: 'APPROVER',
                        submitter: approvers.join(','),
                        parameters: [
                            text(name: 'DEPLOYMENT_NOTES', defaultValue: '', description: 'éƒ¨ç½²è¯´æ˜')
                        ]
                    )
                    
                    echo "éƒ¨ç½²å·²è·å¾— ${deployApproval.APPROVER} çš„æ‰¹å‡†"
                    echo "éƒ¨ç½²è¯´æ˜: ${deployApproval.DEPLOYMENT_NOTES}"
                }
            }
        }

        stage('è“ç»¿éƒ¨ç½²åˆ°ç”Ÿäº§') {
            when {
                expression { params.ENVIRONMENT == 'prod' }
            }
            steps {
                script {
                    // åˆ›å»ºæ–°ç‰ˆæœ¬éƒ¨ç½²
                    sh """
                        # æ›´æ–°é•œåƒç‰ˆæœ¬
                        sed -i 's|image: .*|image: ${DOCKER_REGISTRY}/${DOCKER_NAMESPACE}/${IMAGE_NAME}:${DOCKER_TAG}|g' k8s/prod/deployment.yaml
                        
                        # éƒ¨ç½²åˆ°ç»¿è‰²ç¯å¢ƒ
                        kubectl apply -f k8s/prod/ -n ${K8S_NAMESPACE}-prod-green
                        
                        # ç­‰å¾…éƒ¨ç½²å®Œæˆ
                        kubectl rollout status deployment/${K8S_DEPLOYMENT} -n ${K8S_NAMESPACE}-prod-green --timeout=600s
                    """
                    
                    // å¥åº·æ£€æŸ¥
                    sh '''
                        # å¥åº·æ£€æŸ¥
                        for i in {1..10}; do
                            if kubectl get pods -n notification-system-prod-green | grep -q "Running"; then
                                echo "å¥åº·æ£€æŸ¥é€šè¿‡"
                                break
                            fi
                            sleep 30
                        done
                    '''
                    
                    // åˆ‡æ¢æµé‡
                    timeout(time: 5, unit: 'MINUTES') {
                        input message: 'ç¡®è®¤åˆ‡æ¢ç”Ÿäº§æµé‡ï¼Ÿ', ok: 'ç¡®è®¤åˆ‡æ¢'
                    }
                    
                    sh '''
                        # åˆ‡æ¢æœåŠ¡æŒ‡å‘
                        kubectl patch service notification-service -n notification-system-prod \
                                -p '{"spec":{"selector":{"version":"green"}}}'
                        
                        # éªŒè¯åˆ‡æ¢
                        kubectl get service notification-service -n notification-system-prod -o yaml
                    '''
                }
            }
        }

        stage('éƒ¨ç½²åéªŒè¯') {
            steps {
                sh '''
                    # å¥åº·æ£€æŸ¥
                    curl -f http://notification-service.${ENVIRONMENT}.company.com/actuator/health
                    
                    # ä¸šåŠ¡æ¥å£éªŒè¯
                    curl -f http://notification-service.${ENVIRONMENT}.company.com/api/system/auth/get-permission-info
                    
                    # æ€§èƒ½åŸºå‡†æµ‹è¯•
                    ab -n 100 -c 10 http://notification-service.${ENVIRONMENT}.company.com/api/system/auth/get-permission-info
                '''
            }
        }

        stage('ç›‘æ§å’Œå‘Šè­¦') {
            steps {
                script {
                    // æ›´æ–°Grafana Dashboard
                    sh '''
                        # è§¦å‘ç›‘æ§æ•°æ®åˆ·æ–°
                        curl -X POST "http://grafana.company.com/api/dashboards/db" \
                             -H "Authorization: Bearer ${GRAFANA_API_KEY}" \
                             -H "Content-Type: application/json" \
                             -d @monitoring/grafana-dashboard.json
                    '''
                    
                    // å‘é€éƒ¨ç½²é€šçŸ¥
                    sh '''
                        # é’‰é’‰é€šçŸ¥
                        curl -X POST "${DINGTALK_WEBHOOK}" \
                             -H 'Content-Type: application/json' \
                             -d "{
                                \"msgtype\": \"text\",
                                \"text\": {
                                    \"content\": \"ğŸš€ é€šçŸ¥ç³»ç»Ÿéƒ¨ç½²æˆåŠŸ\\nç¯å¢ƒ: ${ENVIRONMENT}\\nç‰ˆæœ¬: ${BUILD_VERSION}\\nåˆ†æ”¯: ${BRANCH}\\næ„å»ºè€…: ${GIT_AUTHOR}\"
                                }
                             }"
                    '''
                }
            }
        }
    }

    post {
        always {
            // æ¸…ç†å·¥ä½œç©ºé—´
            cleanWs()
            
            // å‘å¸ƒæ„å»ºæŠ¥å‘Š
            publishHTML([
                allowMissing: false,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'target/site',
                reportFiles: 'index.html',
                reportName: 'Maven Site Report'
            ])
        }
        
        success {
            script {
                // æˆåŠŸé€šçŸ¥
                emailext (
                    subject: "âœ… æ„å»ºæˆåŠŸ: ${currentBuild.displayName}",
                    body: """
                        æ„å»ºæˆåŠŸï¼
                        
                        é¡¹ç›®: ${env.JOB_NAME}
                        æ„å»ºå·: ${env.BUILD_NUMBER}
                        ç¯å¢ƒ: ${ENVIRONMENT}
                        ç‰ˆæœ¬: ${BUILD_VERSION}
                        åˆ†æ”¯: ${BRANCH}
                        æäº¤è€…: ${GIT_AUTHOR}
                        
                        æ„å»ºæ—¥å¿—: ${env.BUILD_URL}console
                        éƒ¨ç½²åœ°å€: http://notification-service.${ENVIRONMENT}.company.com
                    """,
                    to: "${GIT_AUTHOR_EMAIL},devops@company.com"
                )
            }
        }
        
        failure {
            script {
                // å¤±è´¥é€šçŸ¥å’Œå›æ»š
                emailext (
                    subject: "âŒ æ„å»ºå¤±è´¥: ${currentBuild.displayName}",
                    body: """
                        æ„å»ºå¤±è´¥ï¼
                        
                        é¡¹ç›®: ${env.JOB_NAME}
                        æ„å»ºå·: ${env.BUILD_NUMBER}
                        ç¯å¢ƒ: ${ENVIRONMENT}
                        åˆ†æ”¯: ${BRANCH}
                        å¤±è´¥åŸå› : ${currentBuild.result}
                        
                        æ„å»ºæ—¥å¿—: ${env.BUILD_URL}console
                        
                        è¯·åŠæ—¶æŸ¥çœ‹å¹¶ä¿®å¤é—®é¢˜ã€‚
                    """,
                    to: "${GIT_AUTHOR_EMAIL},devops@company.com"
                )
                
                // è‡ªåŠ¨å›æ»šï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
                if (params.ENVIRONMENT == 'prod') {
                    sh '''
                        echo "å¼€å§‹è‡ªåŠ¨å›æ»š..."
                        kubectl rollout undo deployment/${K8S_DEPLOYMENT} -n ${K8S_NAMESPACE}-prod
                        kubectl rollout status deployment/${K8S_DEPLOYMENT} -n ${K8S_NAMESPACE}-prod
                    '''
                }
            }
        }
    }
}
```

### 2. GitLab CIé…ç½®

```yaml
# .gitlab-ci.yml
variables:
  MAVEN_OPTS: "-Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository"
  DOCKER_REGISTRY: "harbor.company.com"
  DOCKER_NAMESPACE: "yudao"
  IMAGE_NAME: "notification"
  K8S_NAMESPACE: "notification-system"

stages:
  - validate
  - build
  - test
  - security
  - package
  - deploy-dev
  - deploy-test
  - deploy-prod

cache:
  paths:
    - .m2/repository/
    - node_modules/

# ä»£ç è´¨é‡æ£€æŸ¥
validate:
  stage: validate
  image: maven:3.8.6-openjdk-21-slim
  script:
    - mvn validate
    - mvn compile -DskipTests=true
  only:
    - merge_requests
    - main
    - develop

# æ„å»ºé˜¶æ®µ
build-backend:
  stage: build
  image: maven:3.8.6-openjdk-21-slim
  script:
    - mvn clean compile -DskipTests=true
    - mvn package -DskipTests=true -Pproduction
  artifacts:
    paths:
      - yudao-server/target/*.jar
    expire_in: 1 hour
  only:
    - main
    - develop
    - /^release\/.*$/

build-frontend:
  stage: build
  image: node:18-alpine
  script:
    - cd yudao-ui-admin-vue3
    - npm ci
    - npm run build:prod
  artifacts:
    paths:
      - yudao-ui-admin-vue3/dist/
    expire_in: 1 hour
  only:
    - main
    - develop
    - /^release\/.*$/

# æµ‹è¯•é˜¶æ®µ
unit-test:
  stage: test
  image: maven:3.8.6-openjdk-21-slim
  services:
    - mysql:8.0
    - redis:7.0-alpine
  variables:
    MYSQL_ROOT_PASSWORD: "123456"
    MYSQL_DATABASE: "notification_test"
  script:
    - mvn test
    - mvn jacoco:report
  coverage: '/Total.*?([0-9]{1,3})%/'
  artifacts:
    reports:
      junit:
        - target/surefire-reports/TEST-*.xml
      coverage_report:
        coverage_format: jacoco
        path: target/site/jacoco/jacoco.xml
  only:
    - merge_requests
    - main
    - develop

integration-test:
  stage: test
  image: maven:3.8.6-openjdk-21-slim
  services:
    - mysql:8.0
    - redis:7.0-alpine
    - kafka:latest
  script:
    - mvn test -Dtest=IntegrationTest -Dspring.profiles.active=test
  dependencies:
    - build-backend
  only:
    - main
    - develop

# å®‰å…¨æ‰«æ
sonarqube-scan:
  stage: security
  image: maven:3.8.6-openjdk-21-slim
  script:
    - mvn sonar:sonar 
      -Dsonar.projectKey=notification-system
      -Dsonar.host.url=$SONAR_HOST_URL
      -Dsonar.login=$SONAR_TOKEN
  dependencies:
    - unit-test
  only:
    - main
    - develop
    - merge_requests

dependency-check:
  stage: security
  image: maven:3.8.6-openjdk-21-slim
  script:
    - mvn org.owasp:dependency-check-maven:check
  artifacts:
    reports:
      junit:
        - target/dependency-check-report.xml
  allow_failure: true
  only:
    - main
    - develop

# æ‰“åŒ…Dockeré•œåƒ
package-backend:
  stage: package
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $DOCKER_REGISTRY
  script:
    - cd yudao-server
    - docker build -t $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME:$CI_COMMIT_SHA .
    - docker push $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME:$CI_COMMIT_SHA
    - docker tag $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME:$CI_COMMIT_SHA $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME:latest
    - docker push $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME:latest
  dependencies:
    - build-backend
  only:
    - main
    - develop
    - /^release\/.*$/

package-frontend:
  stage: package
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $DOCKER_REGISTRY
  script:
    - cd yudao-ui-admin-vue3
    - docker build -t $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME-ui:$CI_COMMIT_SHA .
    - docker push $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME-ui:$CI_COMMIT_SHA
    - docker tag $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME-ui:$CI_COMMIT_SHA $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME-ui:latest
    - docker push $DOCKER_REGISTRY/$DOCKER_NAMESPACE/$IMAGE_NAME-ui:latest
  dependencies:
    - build-frontend
  only:
    - main
    - develop
    - /^release\/.*$/

# éƒ¨ç½²å¼€å‘ç¯å¢ƒ
deploy-dev:
  stage: deploy-dev
  image: bitnami/kubectl:latest
  environment:
    name: development
    url: http://notification-dev.company.com
  script:
    - sed -i "s|IMAGE_TAG|$CI_COMMIT_SHA|g" k8s/dev/deployment.yaml
    - kubectl apply -f k8s/dev/ -n $K8S_NAMESPACE-dev
    - kubectl rollout status deployment/notification-app -n $K8S_NAMESPACE-dev
  dependencies:
    - package-backend
    - package-frontend
  only:
    - develop

# éƒ¨ç½²æµ‹è¯•ç¯å¢ƒ
deploy-test:
  stage: deploy-test
  image: bitnami/kubectl:latest
  environment:
    name: testing
    url: http://notification-test.company.com
  script:
    - sed -i "s|IMAGE_TAG|$CI_COMMIT_SHA|g" k8s/test/deployment.yaml
    - kubectl apply -f k8s/test/ -n $K8S_NAMESPACE-test
    - kubectl rollout status deployment/notification-app -n $K8S_NAMESPACE-test
    # è¿è¡Œå†’çƒŸæµ‹è¯•
    - sleep 60
    - curl -f http://notification-service.$K8S_NAMESPACE-test:80/actuator/health
  dependencies:
    - package-backend
    - package-frontend
  only:
    - main

# éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒ
deploy-prod:
  stage: deploy-prod
  image: bitnami/kubectl:latest
  environment:
    name: production
    url: http://notification.company.com
  script:
    - sed -i "s|IMAGE_TAG|$CI_COMMIT_SHA|g" k8s/prod/deployment.yaml
    - kubectl apply -f k8s/prod/ -n $K8S_NAMESPACE-prod
    - kubectl rollout status deployment/notification-app -n $K8S_NAMESPACE-prod
  when: manual
  dependencies:
    - package-backend
    - package-frontend
  only:
    - /^release\/.*$/
    - main
```

## ğŸ“Š Prometheusç›‘æ§é…ç½®

### 1. Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'notification-cluster'
    region: 'beijing'

rule_files:
  - "notification-rules.yml"
  - "infrastructure-rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # åº”ç”¨ç›‘æ§
  - job_name: 'notification-app'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - notification-system
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: keep
        regex: notification-app
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
    scrape_interval: 30s
    metrics_path: /actuator/prometheus

  # MySQLç›‘æ§
  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']
    scrape_interval: 30s

  # Redisç›‘æ§
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    scrape_interval: 30s

  # Kafkaç›‘æ§
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka-exporter:9308']
    scrape_interval: 30s

  # Kubernetesç›‘æ§
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

  # Nodeç›‘æ§
  - job_name: 'node-exporter'
    kubernetes_sd_configs:
      - role: endpoints
    relabel_configs:
      - source_labels: [__meta_kubernetes_endpoints_name]
        action: keep
        regex: node-exporter

  # JVMç›‘æ§
  - job_name: 'jvm-metrics'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - notification-system
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: keep
        regex: notification-app
    metrics_path: /actuator/prometheus
    scrape_interval: 15s
```

### 2. å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# notification-rules.yml
groups:
  - name: notification-app-alerts
    rules:
      # åº”ç”¨å¯ç”¨æ€§å‘Šè­¦
      - alert: ApplicationDown
        expr: up{job="notification-app"} == 0
        for: 1m
        labels:
          severity: critical
          service: notification-app
        annotations:
          summary: "é€šçŸ¥åº”ç”¨æœåŠ¡ä¸å¯ç”¨"
          description: "åº”ç”¨ {{ $labels.instance }} å·²ç»ç¦»çº¿è¶…è¿‡1åˆ†é’Ÿ"

      # å†…å­˜ä½¿ç”¨å‘Šè­¦
      - alert: HighMemoryUsage
        expr: (jvm_memory_used_bytes{job="notification-app"} / jvm_memory_max_bytes{job="notification-app"}) * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: notification-app
        annotations:
          summary: "åº”ç”¨å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®ä¾‹ {{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%"

      # CPUä½¿ç”¨å‘Šè­¦
      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total{job="notification-app"}[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: notification-app
        annotations:
          summary: "åº”ç”¨CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®ä¾‹ {{ $labels.instance }} CPUä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%"

      # GCé¢‘ç¹å‘Šè­¦
      - alert: FrequentGC
        expr: rate(jvm_gc_collection_seconds_count{job="notification-app"}[5m]) > 5
        for: 2m
        labels:
          severity: warning
          service: notification-app
        annotations:
          summary: "JVM GCè¿‡äºé¢‘ç¹"
          description: "å®ä¾‹ {{ $labels.instance }} GCé¢‘ç‡ä¸º {{ $value }} æ¬¡/ç§’"

      # å“åº”æ—¶é—´å‘Šè­¦
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_server_requests_seconds_bucket{job="notification-app"}[5m])) > 5
        for: 3m
        labels:
          severity: warning
          service: notification-app
        annotations:
          summary: "æ¥å£å“åº”æ—¶é—´è¿‡é•¿"
          description: "95%æ¥å£å“åº”æ—¶é—´è¶…è¿‡5ç§’ï¼Œå½“å‰å€¼: {{ $value }}s"

      # é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: (rate(http_server_requests_seconds_count{job="notification-app",status=~"5.."}[5m]) / rate(http_server_requests_seconds_count{job="notification-app"}[5m])) * 100 > 5
        for: 2m
        labels:
          severity: critical
          service: notification-app
        annotations:
          summary: "åº”ç”¨é”™è¯¯ç‡è¿‡é«˜"
          description: "5xxé”™è¯¯ç‡è¾¾åˆ° {{ $value }}%"

      # æ•°æ®åº“è¿æ¥æ± å‘Šè­¦
      - alert: DatabaseConnectionPoolHigh
        expr: hikaricp_connections_active{job="notification-app"} / hikaricp_connections_max{job="notification-app"} * 100 > 80
        for: 3m
        labels:
          severity: warning
          service: notification-app
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡è¿‡é«˜"
          description: "è¿æ¥æ± ä½¿ç”¨ç‡è¾¾åˆ° {{ $value }}%"

      # æ¨é€é˜Ÿåˆ—ç§¯å‹å‘Šè­¦
      - alert: PushQueueBacklog
        expr: kafka_consumer_lag_sum{job="kafka-exporter", topic="notification_push"} > 1000
        for: 2m
        labels:
          severity: warning
          service: notification-push
        annotations:
          summary: "æ¨é€é˜Ÿåˆ—ç§¯å‹ä¸¥é‡"
          description: "æ¨é€é˜Ÿåˆ—ç§¯å‹æ¶ˆæ¯æ•°: {{ $value }}"

      # æ¨é€æˆåŠŸç‡å‘Šè­¦
      - alert: LowPushSuccessRate
        expr: (rate(notification_push_success_total[5m]) / (rate(notification_push_success_total[5m]) + rate(notification_push_failure_total[5m]))) * 100 < 95
        for: 3m
        labels:
          severity: warning
          service: notification-push
        annotations:
          summary: "æ¨é€æˆåŠŸç‡è¿‡ä½"
          description: "æ¨é€æˆåŠŸç‡ä»…ä¸º {{ $value }}%"

  - name: infrastructure-alerts
    rules:
      # MySQLå‘Šè­¦
      - alert: MySQLDown
        expr: up{job="mysql"} == 0
        for: 1m
        labels:
          severity: critical
          service: mysql
        annotations:
          summary: "MySQLæ•°æ®åº“ä¸å¯ç”¨"
          description: "MySQLå®ä¾‹ {{ $labels.instance }} æ— æ³•è¿æ¥"

      - alert: MySQLSlowQueries
        expr: rate(mysql_global_status_slow_queries[5m]) > 0.2
        for: 3m
        labels:
          severity: warning
          service: mysql
        annotations:
          summary: "MySQLæ…¢æŸ¥è¯¢å¢å¤š"
          description: "æ…¢æŸ¥è¯¢ç‡: {{ $value }} æŸ¥è¯¢/ç§’"

      - alert: MySQLConnectionsHigh
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections * 100 > 80
        for: 3m
        labels:
          severity: warning
          service: mysql
        annotations:
          summary: "MySQLè¿æ¥æ•°è¿‡é«˜"
          description: "è¿æ¥ä½¿ç”¨ç‡è¾¾åˆ° {{ $value }}%"

      # Rediså‘Šè­¦
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          service: redis
        annotations:
          summary: "Redisç¼“å­˜ä¸å¯ç”¨"
          description: "Rediså®ä¾‹ {{ $labels.instance }} æ— æ³•è¿æ¥"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Rediså†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ° {{ $value }}%"

      # Kafkaå‘Šè­¦
      - alert: KafkaDown
        expr: up{job="kafka"} == 0
        for: 1m
        labels:
          severity: critical
          service: kafka
        annotations:
          summary: "Kafkaæ¶ˆæ¯é˜Ÿåˆ—ä¸å¯ç”¨"
          description: "Kafkaå®ä¾‹ {{ $labels.instance }} æ— æ³•è¿æ¥"

      - alert: KafkaConsumerLag
        expr: kafka_consumer_lag_sum > 5000
        for: 3m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafkaæ¶ˆè´¹å»¶è¿Ÿè¿‡é«˜"
          description: "æ¶ˆè´¹å»¶è¿Ÿ: {{ $value }} æ¡æ¶ˆæ¯"
```

### 3. Grafanaç›‘æ§é¢æ¿

```json
{
  "dashboard": {
    "id": null,
    "title": "æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿç›‘æ§å¤§å±",
    "tags": ["notification", "yudao"],
    "timezone": "Asia/Shanghai",
    "panels": [
      {
        "id": 1,
        "title": "ç³»ç»Ÿæ¦‚è§ˆ",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"notification-app\"}",
            "legendFormat": "æœåŠ¡å®ä¾‹æ•°"
          },
          {
            "expr": "sum(rate(http_server_requests_seconds_count{job=\"notification-app\"}[5m]))",
            "legendFormat": "è¯·æ±‚QPS"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_server_requests_seconds_bucket{job=\"notification-app\"}[5m]))",
            "legendFormat": "P95å“åº”æ—¶é—´"
          },
          {
            "expr": "(1 - sum(rate(http_server_requests_seconds_count{job=\"notification-app\",status=~\"5..\"}[5m])) / sum(rate(http_server_requests_seconds_count{job=\"notification-app\"}[5m]))) * 100",
            "legendFormat": "æˆåŠŸç‡(%)"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "JVMå†…å­˜ä½¿ç”¨æƒ…å†µ",
        "type": "timeseries",
        "targets": [
          {
            "expr": "jvm_memory_used_bytes{job=\"notification-app\", area=\"heap\"}",
            "legendFormat": "å †å†…å­˜ä½¿ç”¨-{{instance}}"
          },
          {
            "expr": "jvm_memory_max_bytes{job=\"notification-app\", area=\"heap\"}",
            "legendFormat": "å †å†…å­˜æœ€å¤§å€¼-{{instance}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 3,
        "title": "GCæƒ…å†µ",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rate(jvm_gc_collection_seconds_count{job=\"notification-app\"}[5m])",
            "legendFormat": "GCæ¬¡æ•°/ç§’-{{gc}}"
          },
          {
            "expr": "rate(jvm_gc_collection_seconds_sum{job=\"notification-app\"}[5m])",
            "legendFormat": "GCæ—¶é—´/ç§’-{{gc}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 4,
        "title": "æ¥å£è¯·æ±‚ç»Ÿè®¡",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(rate(http_server_requests_seconds_count{job=\"notification-app\"}[5m])) by (uri)",
            "legendFormat": "{{uri}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16}
      },
      {
        "id": 5,
        "title": "æ¨é€ä¸šåŠ¡ç›‘æ§",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(rate(notification_push_total[5m]))",
            "legendFormat": "æ¨é€æ€»æ•°/ç§’"
          },
          {
            "expr": "sum(rate(notification_push_success_total[5m]))",
            "legendFormat": "æ¨é€æˆåŠŸ/ç§’"
          },
          {
            "expr": "sum(rate(notification_push_failure_total[5m]))",
            "legendFormat": "æ¨é€å¤±è´¥/ç§’"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16}
      },
      {
        "id": 6,
        "title": "æ•°æ®åº“è¿æ¥æ± ",
        "type": "timeseries",
        "targets": [
          {
            "expr": "hikaricp_connections_active{job=\"notification-app\"}",
            "legendFormat": "æ´»è·ƒè¿æ¥æ•°"
          },
          {
            "expr": "hikaricp_connections_idle{job=\"notification-app\"}",
            "legendFormat": "ç©ºé—²è¿æ¥æ•°"
          },
          {
            "expr": "hikaricp_connections_max{job=\"notification-app\"}",
            "legendFormat": "æœ€å¤§è¿æ¥æ•°"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24}
      },
      {
        "id": 7,
        "title": "Redisæ€§èƒ½ç›‘æ§",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rate(redis_commands_processed_total[5m])",
            "legendFormat": "å‘½ä»¤æ‰§è¡Œæ•°/ç§’"
          },
          {
            "expr": "redis_connected_clients",
            "legendFormat": "è¿æ¥å®¢æˆ·ç«¯æ•°"
          },
          {
            "expr": "redis_memory_used_bytes / 1024 / 1024",
            "legendFormat": "å†…å­˜ä½¿ç”¨(MB)"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24}
      },
      {
        "id": 8,
        "title": "Kafkaæ¶ˆæ¯é˜Ÿåˆ—",
        "type": "timeseries",
        "targets": [
          {
            "expr": "kafka_topic_partition_current_offset",
            "legendFormat": "å½“å‰offset-{{topic}}"
          },
          {
            "expr": "kafka_consumer_lag_sum",
            "legendFormat": "æ¶ˆè´¹å»¶è¿Ÿ-{{topic}}"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

## ğŸ“‹ ELKæ—¥å¿—æ”¶é›†é…ç½®

### 1. Logstashé…ç½®

```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "notification-app" {
    # è§£æåº”ç”¨æ—¥å¿—
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:thread}\] %{DATA:logger} - %{GREEDYDATA:message}"
      }
    }
    
    # è§£æJSONæ ¼å¼æ—¥å¿—
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
      }
    }
    
    # æ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯
    if [client_ip] {
      geoip {
        source => "client_ip"
        target => "geoip"
      }
    }
    
    # æ—¶é—´è§£æ
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
      target => "@timestamp"
    }
    
    # æ·»åŠ æ ‡ç­¾
    mutate {
      add_tag => [ "notification-app", "spring-boot" ]
      add_field => { "service_name" => "notification-system" }
    }
  }
  
  if [fields][service] == "mysql" {
    # MySQLæ…¢æ—¥å¿—è§£æ
    grok {
      match => { 
        "message" => "# Time: %{TIMESTAMP_ISO8601:timestamp}\n# User@Host: %{USER:user}\[%{USER:user_host}\] @ %{IPORHOST:client_host} \[%{IPORHOST:client_ip}\]\n# Query_time: %{NUMBER:query_time:float} Lock_time: %{NUMBER:lock_time:float} Rows_sent: %{NUMBER:rows_sent:int} Rows_examined: %{NUMBER:rows_examined:int}\n%{GREEDYDATA:sql_query}"
      }
    }
    
    if [query_time] and [query_time] > 1 {
      mutate {
        add_tag => [ "slow-query" ]
      }
    }
  }
  
  if [fields][service] == "nginx" {
    # Nginxè®¿é—®æ—¥å¿—è§£æ
    grok {
      match => { 
        "message" => "%{NGINXACCESS}"
      }
    }
    
    # è®¡ç®—å“åº”æ—¶é—´ç­‰çº§
    if [response_time] {
      if [response_time] > 5 {
        mutate { add_tag => [ "slow-response" ] }
      } else if [response_time] > 1 {
        mutate { add_tag => [ "medium-response" ] }
      } else {
        mutate { add_tag => [ "fast-response" ] }
      }
    }
  }
}

output {
  if "notification-app" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "notification-app-%{+YYYY.MM.dd}"
      template_name => "notification-app"
    }
  }
  
  if "mysql" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "mysql-logs-%{+YYYY.MM.dd}"
    }
  }
  
  if "nginx" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "nginx-access-%{+YYYY.MM.dd}"
    }
  }
  
  # è°ƒè¯•è¾“å‡º
  if [level] == "ERROR" {
    stdout {
      codec => rubydebug
    }
  }
}
```

### 2. Filebeaté…ç½®

```yaml
# filebeat.yml
filebeat.inputs:
  # åº”ç”¨æ—¥å¿—æ”¶é›†
  - type: log
    enabled: true
    paths:
      - /app/logs/*.log
    fields:
      service: notification-app
      environment: production
    fields_under_root: true
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after
    exclude_lines: ['^DBG']
    
  # MySQLæ—¥å¿—æ”¶é›†
  - type: log
    enabled: true
    paths:
      - /var/log/mysql/slow.log
      - /var/log/mysql/error.log
    fields:
      service: mysql
      log_type: database
    
  # Nginxæ—¥å¿—æ”¶é›†
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access.log
      - /var/log/nginx/error.log
    fields:
      service: nginx
      log_type: webserver

processors:
  # æ·»åŠ Dockerå®¹å™¨ä¿¡æ¯
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"
  
  # æ·»åŠ Kuberneteså…ƒæ•°æ®
  - add_kubernetes_metadata:
      host: ${NODE_NAME}
      matchers:
      - logs_path:
          logs_path: "/var/log/containers/"
  
  # åˆ é™¤æ•æ„Ÿå­—æ®µ
  - drop_fields:
      fields: ["host.name", "agent.name"]

output.logstash:
  hosts: ["logstash:5044"]
  compression_level: 3
  bulk_max_size: 2048

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0640

monitoring.enabled: true
```

### 3. Kibana Dashboardé…ç½®

```json
{
  "version": "7.15.0",
  "objects": [
    {
      "attributes": {
        "title": "é€šçŸ¥ç³»ç»Ÿæ—¥å¿—åˆ†æ",
        "type": "dashboard",
        "description": "æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿç»¼åˆæ—¥å¿—åˆ†æé¢æ¿",
        "panelsJSON": "[{\"version\":\"7.15.0\",\"gridData\":{\"x\":0,\"y\":0,\"w\":24,\"h\":15,\"i\":\"1\"},\"panelIndex\":\"1\",\"embeddableConfig\":{},\"panelRefName\":\"panel_1\"}]",
        "timeRestore": true,
        "timeTo": "now",
        "timeFrom": "now-24h",
        "refreshInterval": {
          "pause": false,
          "value": 30000
        },
        "kibanaSavedObjectMeta": {
          "searchSourceJSON": "{\"query\":{\"match_all\":{}},\"filter\":[]}"
        }
      },
      "references": [
        {
          "name": "panel_1",
          "type": "visualization",
          "id": "log-levels-pie"
        }
      ]
    },
    {
      "attributes": {
        "title": "æ—¥å¿—çº§åˆ«åˆ†å¸ƒ",
        "visState": "{\"title\":\"æ—¥å¿—çº§åˆ«åˆ†å¸ƒ\",\"type\":\"pie\",\"params\":{\"addTooltip\":true,\"addLegend\":true,\"legendPosition\":\"right\"},\"aggs\":[{\"id\":\"1\",\"type\":\"count\",\"schema\":\"metric\",\"params\":{}},{\"id\":\"2\",\"type\":\"terms\",\"schema\":\"segment\",\"params\":{\"field\":\"level.keyword\",\"size\":5,\"order\":\"desc\",\"orderBy\":\"1\"}}]}",
        "uiStateJSON": "{}",
        "description": "",
        "version": 1,
        "kibanaSavedObjectMeta": {
          "searchSourceJSON": "{\"index\":\"notification-app-*\",\"query\":{\"match_all\":{}},\"filter\":[]}"
        }
      },
      "id": "log-levels-pie",
      "type": "visualization"
    }
  ]
}
```

## ğŸš¨ å‘Šè­¦æœºåˆ¶é…ç½®

### 1. AlertManageré…ç½®

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.company.com:587'
  smtp_from: 'alertmanager@company.com'
  smtp_auth_username: 'alertmanager@company.com'
  smtp_auth_password: 'password'

templates:
  - '/etc/alertmanager/templates/*.tmpl'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
    # ç´§æ€¥å‘Šè­¦
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m
    
    # è­¦å‘Šå‘Šè­¦
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 30s
      repeat_interval: 30m
    
    # ä¸šåŠ¡å‘Šè­¦
    - match:
        service: notification-push
      receiver: 'business-alerts'

receivers:
  - name: 'default'
    email_configs:
      - to: 'devops@company.com'
        subject: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        body: |
          {{ range .Alerts }}
          å‘Šè­¦åç§°: {{ .Annotations.summary }}
          å‘Šè­¦è¯¦æƒ…: {{ .Annotations.description }}
          å‘Šè­¦æ—¶é—´: {{ .StartsAt }}
          å‘Šè­¦çº§åˆ«: {{ .Labels.severity }}
          æœåŠ¡åç§°: {{ .Labels.service }}
          å®ä¾‹åœ°å€: {{ .Labels.instance }}
          {{ end }}

  - name: 'critical-alerts'
    # é‚®ä»¶é€šçŸ¥
    email_configs:
      - to: 'devops@company.com,dev-lead@company.com'
        subject: 'ğŸš¨ ç´§æ€¥å‘Šè­¦: {{ .GroupLabels.alertname }}'
        
    # é’‰é’‰é€šçŸ¥
    webhook_configs:
      - url: 'http://webhook-service:8080/dingtalk/critical'
        send_resolved: true
        
    # çŸ­ä¿¡é€šçŸ¥
    webhook_configs:
      - url: 'http://webhook-service:8080/sms/critical'
        send_resolved: false

  - name: 'warning-alerts'
    email_configs:
      - to: 'devops@company.com'
        subject: 'âš ï¸ è­¦å‘Šå‘Šè­¦: {{ .GroupLabels.alertname }}'
        
    webhook_configs:
      - url: 'http://webhook-service:8080/dingtalk/warning'
        send_resolved: true

  - name: 'business-alerts'
    webhook_configs:
      - url: 'http://webhook-service:8080/dingtalk/business'
        send_resolved: true
        
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

### 2. è‡ªåŠ¨æ¢å¤è„šæœ¬

```bash
#!/bin/bash
# auto-recovery.sh

# å‘Šè­¦å¤„ç†å‡½æ•°
handle_alert() {
    local alert_name=$1
    local instance=$2
    local severity=$3
    
    echo "å¤„ç†å‘Šè­¦: $alert_name, å®ä¾‹: $instance, çº§åˆ«: $severity"
    
    case $alert_name in
        "ApplicationDown")
            restart_application $instance
            ;;
        "HighMemoryUsage")
            cleanup_memory $instance
            ;;
        "DatabaseConnectionPoolHigh")
            restart_database_connection_pool $instance
            ;;
        "KafkaConsumerLag")
            scale_up_consumers
            ;;
        *)
            echo "æœªçŸ¥å‘Šè­¦ç±»å‹ï¼Œä»…è®°å½•æ—¥å¿—"
            ;;
    esac
}

# é‡å¯åº”ç”¨
restart_application() {
    local instance=$1
    echo "é‡å¯åº”ç”¨å®ä¾‹: $instance"
    
    # è·å–Podåç§°
    local pod_name=$(kubectl get pods -n notification-system | grep $instance | awk '{print $1}')
    
    if [ -n "$pod_name" ]; then
        kubectl delete pod $pod_name -n notification-system
        echo "å·²åˆ é™¤Pod: $pod_nameï¼Œç­‰å¾…é‡æ–°åˆ›å»º"
        
        # ç­‰å¾…Podé‡æ–°å¯åŠ¨
        sleep 30
        kubectl wait --for=condition=Ready pod -l app=notification-app -n notification-system --timeout=300s
        
        # å‘é€æ¢å¤é€šçŸ¥
        send_recovery_notification "åº”ç”¨å®ä¾‹ $instance å·²è‡ªåŠ¨é‡å¯"
    fi
}

# å†…å­˜æ¸…ç†
cleanup_memory() {
    local instance=$1
    echo "æ¸…ç†å†…å­˜: $instance"
    
    # è§¦å‘GC
    curl -X POST "http://$instance/actuator/gc"
    
    # å¦‚æœå†…å­˜ä½¿ç”¨ä»ç„¶è¿‡é«˜ï¼Œé‡å¯åº”ç”¨
    sleep 60
    local memory_usage=$(check_memory_usage $instance)
    if [ $memory_usage -gt 80 ]; then
        restart_application $instance
    fi
}

# æ‰©å±•æ¶ˆè´¹è€…
scale_up_consumers() {
    echo "æ‰©å±•Kafkaæ¶ˆè´¹è€…"
    
    # å¢åŠ æ¶ˆè´¹è€…å‰¯æœ¬æ•°
    kubectl scale deployment notification-consumer -n notification-system --replicas=6
    
    # ç­‰å¾…æ‰©å®¹å®Œæˆ
    kubectl rollout status deployment notification-consumer -n notification-system
    
    send_recovery_notification "å·²è‡ªåŠ¨æ‰©å±•Kafkaæ¶ˆè´¹è€…è‡³6ä¸ªå‰¯æœ¬"
}

# å‘é€æ¢å¤é€šçŸ¥
send_recovery_notification() {
    local message=$1
    
    curl -X POST "${DINGTALK_WEBHOOK}" \
         -H 'Content-Type: application/json' \
         -d "{
            \"msgtype\": \"text\",
            \"text\": {
                \"content\": \"ğŸ”§ è‡ªåŠ¨æ¢å¤é€šçŸ¥: $message\"
            }
         }"
}

# æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
check_memory_usage() {
    local instance=$1
    # é€šè¿‡Prometheus APIè·å–å†…å­˜ä½¿ç”¨ç‡
    curl -s "http://prometheus:9090/api/v1/query?query=jvm_memory_used_bytes{instance=\"$instance\"}/jvm_memory_max_bytes{instance=\"$instance\"}*100" | jq -r '.data.result[0].value[1]' | cut -d. -f1
}

# ä¸»å‡½æ•°
main() {
    # ä»webhookæ¥æ”¶å‘Šè­¦ä¿¡æ¯
    while read line; do
        if echo $line | jq -e .alerts > /dev/null 2>&1; then
            alerts=$(echo $line | jq -r '.alerts[]')
            for alert in $alerts; do
                alert_name=$(echo $alert | jq -r '.labels.alertname')
                instance=$(echo $alert | jq -r '.labels.instance')
                severity=$(echo $alert | jq -r '.labels.severity')
                status=$(echo $alert | jq -r '.status')
                
                if [ "$status" = "firing" ]; then
                    handle_alert $alert_name $instance $severity
                fi
            done
        fi
    done
}

# å¯åŠ¨è‡ªåŠ¨æ¢å¤æœåŠ¡
if [ "$1" = "start" ]; then
    echo "å¯åŠ¨è‡ªåŠ¨æ¢å¤æœåŠ¡"
    nc -l -k -p 9099 | main
else
    echo "ç”¨æ³•: $0 start"
fi
```

## ğŸ“Š æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

### 1. JVMç›‘æ§é…ç½®

```yaml
# jvm-monitoring.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: jvm-monitoring-config
  namespace: notification-system
data:
  jvm-opts: |
    # GCæ—¥å¿—é…ç½®
    -XX:+UseG1GC
    -XX:MaxGCPauseMillis=200
    -XX:+UnlockExperimentalVMOptions
    -XX:+UseContainerSupport
    
    # å†…å­˜dumpé…ç½®
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:HeapDumpPath=/app/dumps/
    -XX:+ExitOnOutOfMemoryError
    
    # GCæ—¥å¿—
    -Xlog:gc*:logs/gc.log:time,tags
    -Xlog:gc-heap-coops
    
    # JMXç›‘æ§
    -Dcom.sun.management.jmxremote=true
    -Dcom.sun.management.jmxremote.port=1099
    -Dcom.sun.management.jmxremote.authenticate=false
    -Dcom.sun.management.jmxremote.ssl=false
    
    # APM Agent
    -javaagent:/app/apm/skywalking-agent.jar
    -Dskywalking.agent.service_name=notification-system
    -Dskywalking.collector.backend_service=skywalking-oap:11800
```

### 2. APMé…ç½®

```yaml
# skywalking-oap.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: skywalking-oap
  namespace: notification-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: skywalking-oap
  template:
    metadata:
      labels:
        app: skywalking-oap
    spec:
      containers:
      - name: skywalking-oap
        image: apache/skywalking-oap-server:8.9.1
        ports:
        - containerPort: 11800
        - containerPort: 12800
        env:
        - name: SW_STORAGE
          value: elasticsearch
        - name: SW_STORAGE_ES_CLUSTER_NODES
          value: "elasticsearch:9200"
        - name: SW_TELEMETRY
          value: prometheus
        - name: JAVA_OPTS
          value: "-Xms2g -Xmx2g"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: skywalking-ui
  namespace: notification-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: skywalking-ui
  template:
    metadata:
      labels:
        app: skywalking-ui
    spec:
      containers:
      - name: skywalking-ui
        image: apache/skywalking-ui:8.9.1
        ports:
        - containerPort: 8080
        env:
        - name: SW_OAP_ADDRESS
          value: "skywalking-oap:12800"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
```

## ğŸ“ˆ å®¹é‡è§„åˆ’å’Œæ‰©å®¹ç­–ç•¥

### 1. è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®

```yaml
# hpa-vpa.yml
# æ°´å¹³æ‰©ç¼©å®¹
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: notification-app-hpa
  namespace: notification-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: notification-app
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60

---
# å‚ç›´æ‰©ç¼©å®¹
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: notification-app-vpa
  namespace: notification-system
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: notification-app
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: notification-app
      minAllowed:
        cpu: 100m
        memory: 512Mi
      maxAllowed:
        cpu: 4
        memory: 8Gi
      controlledResources: ["cpu", "memory"]
```

### 2. é›†ç¾¤è‡ªåŠ¨æ‰©å®¹

```yaml
# cluster-autoscaler.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      containers:
      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.21.0
        name: cluster-autoscaler
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 300Mi
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/notification-cluster
        - --balance-similar-node-groups
        - --skip-nodes-with-system-pods=false
        env:
        - name: AWS_REGION
          value: cn-north-1
        volumeMounts:
        - name: ssl-certs
          mountPath: /etc/ssl/certs/ca-certificates.crt
          readOnly: true
      volumes:
      - name: ssl-certs
        hostPath:
          path: "/etc/ssl/certs/ca-certificates.crt"
```

## ğŸ”’ å®‰å…¨ç›‘æ§é…ç½®

### 1. å®‰å…¨æ‰«æ

```yaml
# security-scanning.yml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: security-scan
  namespace: notification-system
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: trivy-scanner
            image: aquasec/trivy:latest
            command:
            - /bin/sh
            - -c
            - |
              # æ‰«æè¿è¡Œä¸­çš„é•œåƒ
              trivy image --format json --output /reports/backend-scan.json harbor.company.com/yudao/notification:latest
              trivy image --format json --output /reports/frontend-scan.json harbor.company.com/yudao/notification-ui:latest
              
              # æ‰«ææ–‡ä»¶ç³»ç»Ÿ
              trivy fs --format json --output /reports/filesystem-scan.json /app
              
              # å‘é€æŠ¥å‘Š
              curl -X POST "http://webhook-service:8080/security-report" \
                   -H "Content-Type: application/json" \
                   -d @/reports/backend-scan.json
            volumeMounts:
            - name: scan-reports
              mountPath: /reports
          volumes:
          - name: scan-reports
            emptyDir: {}
          restartPolicy: OnFailure
```

### 2. å…¥ä¾µæ£€æµ‹

```yaml
# falco-rules.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: falco-rules
  namespace: notification-system
data:
  notification_rules.yaml: |
    - rule: Suspicious Network Activity
      desc: Detect suspicious network connections
      condition: >
        spawned_process and container.name startswith "notification-app" and
        (proc.name in (nc, ncat, netcat, socat) or
         (proc.name = "curl" and proc.args contains "shell"))
      output: >
        Suspicious network activity in notification container 
        (user=%user.name command=%proc.cmdline container=%container.name)
      priority: WARNING
      tags: [network, suspicious]
    
    - rule: Unexpected File Access
      desc: Detect unexpected file access in application
      condition: >
        open_read and container.name startswith "notification-app" and
        (fd.name startswith "/etc/passwd" or
         fd.name startswith "/etc/shadow" or
         fd.name startswith "/proc/")
      output: >
        Unexpected file access in notification container 
        (user=%user.name file=%fd.name container=%container.name)
      priority: WARNING
      tags: [filesystem, security]
    
    - rule: Privileged Container Launch
      desc: Detect privileged container launch
      condition: >
        container_started and container.privileged = true and
        container.name contains "notification"
      output: >
        Privileged notification container launched 
        (user=%user.name container=%container.name)
      priority: HIGH
      tags: [container, privileged]
```

## ğŸ“‹ éƒ¨ç½²æ¸…å•å’Œæœ€ä½³å®è·µ

### 1. ç¯å¢ƒæ¸…å•æ£€æŸ¥

```bash
#!/bin/bash
# deployment-checklist.sh

echo "=== æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿéƒ¨ç½²å‰æ£€æŸ¥æ¸…å• ==="

# åŸºç¡€è®¾æ–½æ£€æŸ¥
check_infrastructure() {
    echo "1. åŸºç¡€è®¾æ–½æ£€æŸ¥"
    
    # Kubernetesé›†ç¾¤
    if kubectl cluster-info > /dev/null 2>&1; then
        echo "âœ… Kubernetesé›†ç¾¤è¿æ¥æ­£å¸¸"
        kubectl version --short
    else
        echo "âŒ Kubernetesé›†ç¾¤è¿æ¥å¤±è´¥"
        return 1
    fi
    
    # Docker Registry
    if docker login $DOCKER_REGISTRY > /dev/null 2>&1; then
        echo "âœ… Docker Registryè¿æ¥æ­£å¸¸"
    else
        echo "âŒ Docker Registryè¿æ¥å¤±è´¥"
        return 1
    fi
    
    # å­˜å‚¨æ£€æŸ¥
    echo "å­˜å‚¨ç±»æ£€æŸ¥:"
    kubectl get storageclass
    
    # ç½‘ç»œæ£€æŸ¥
    echo "ç½‘ç»œç­–ç•¥æ£€æŸ¥:"
    kubectl get networkpolicy -A
}

# èµ„æºé…é¢æ£€æŸ¥
check_resources() {
    echo "2. èµ„æºé…é¢æ£€æŸ¥"
    
    # èŠ‚ç‚¹èµ„æº
    echo "èŠ‚ç‚¹èµ„æºçŠ¶æ€:"
    kubectl top nodes
    
    # å‘½åç©ºé—´èµ„æºé…é¢
    echo "å‘½åç©ºé—´èµ„æºé…é¢:"
    kubectl get resourcequota -n notification-system
    
    # PVçŠ¶æ€
    echo "æŒä¹…å·çŠ¶æ€:"
    kubectl get pv | grep Available
}

# é…ç½®æ£€æŸ¥
check_configurations() {
    echo "3. é…ç½®æ£€æŸ¥"
    
    # ConfigMaps
    echo "é…ç½®æ˜ å°„æ£€æŸ¥:"
    kubectl get configmap -n notification-system
    
    # Secrets
    echo "å¯†é’¥æ£€æŸ¥:"
    kubectl get secret -n notification-system
    
    # ç½‘ç»œæœåŠ¡
    echo "æœåŠ¡æ£€æŸ¥:"
    kubectl get svc -n notification-system
}

# ç›‘æ§æ£€æŸ¥
check_monitoring() {
    echo "4. ç›‘æ§ç³»ç»Ÿæ£€æŸ¥"
    
    # Prometheus
    if curl -s http://prometheus:9090/-/healthy > /dev/null; then
        echo "âœ… Prometheusè¿è¡Œæ­£å¸¸"
    else
        echo "âŒ Prometheusè¿æ¥å¤±è´¥"
    fi
    
    # Grafana
    if curl -s http://grafana:3000/api/health > /dev/null; then
        echo "âœ… Grafanaè¿è¡Œæ­£å¸¸"
    else
        echo "âŒ Grafanaè¿æ¥å¤±è´¥"
    fi
    
    # Elasticsearch
    if curl -s http://elasticsearch:9200/_cluster/health > /dev/null; then
        echo "âœ… Elasticsearchè¿è¡Œæ­£å¸¸"
    else
        echo "âŒ Elasticsearchè¿æ¥å¤±è´¥"
    fi
}

# å®‰å…¨æ£€æŸ¥
check_security() {
    echo "5. å®‰å…¨é…ç½®æ£€æŸ¥"
    
    # RBAC
    echo "RBACæƒé™æ£€æŸ¥:"
    kubectl get clusterrolebinding | grep notification
    
    # ç½‘ç»œç­–ç•¥
    echo "ç½‘ç»œç­–ç•¥æ£€æŸ¥:"
    kubectl get networkpolicy -n notification-system
    
    # Podå®‰å…¨ç­–ç•¥
    echo "Podå®‰å…¨ç­–ç•¥æ£€æŸ¥:"
    kubectl get psp | grep notification
    
    # é•œåƒå®‰å…¨æ‰«æ
    echo "é•œåƒå®‰å…¨æ‰«æ:"
    trivy image --severity HIGH,CRITICAL $DOCKER_REGISTRY/yudao/notification:latest
}

# æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥
main() {
    check_infrastructure
    check_resources  
    check_configurations
    check_monitoring
    check_security
    
    echo ""
    echo "=== éƒ¨ç½²å‰æ£€æŸ¥å®Œæˆ ==="
    echo "å¦‚æ‰€æœ‰æ£€æŸ¥é¡¹é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹éƒ¨ç½²"
}

main "$@"
```

### 2. éƒ¨ç½²æœ€ä½³å®è·µæ–‡æ¡£

```markdown
# æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿéƒ¨ç½²æœ€ä½³å®è·µ

## éƒ¨ç½²å‰å‡†å¤‡

### 1. ç¯å¢ƒè¦æ±‚
- Kubernetes 1.21+
- Docker 20.10+
- Helm 3.6+
- kubectl 1.21+

### 2. èµ„æºè§„åˆ’
```yaml
ç”Ÿäº§ç¯å¢ƒæœ€å°é…ç½®:
  èŠ‚ç‚¹æ•°é‡: 5ä¸ª
  å•èŠ‚ç‚¹é…ç½®: 8C16G
  å­˜å‚¨: 500GB SSD
  ç½‘ç»œå¸¦å®½: 10Gbps
```

### 3. å®‰å…¨é…ç½®
- å¯ç”¨RBACæƒé™æ§åˆ¶
- é…ç½®ç½‘ç»œç­–ç•¥éš”ç¦»
- å¯ç”¨Podå®‰å…¨ç­–ç•¥
- é…ç½®é•œåƒå®‰å…¨æ‰«æ

## éƒ¨ç½²æµç¨‹

### é˜¶æ®µ1: åŸºç¡€è®¾æ–½éƒ¨ç½²
1. åˆ›å»ºå‘½åç©ºé—´
2. éƒ¨ç½²å­˜å‚¨ç»„ä»¶
3. é…ç½®ç½‘ç»œç­–ç•¥
4. éƒ¨ç½²ç›‘æ§ç³»ç»Ÿ

### é˜¶æ®µ2: æ•°æ®å­˜å‚¨éƒ¨ç½²
1. éƒ¨ç½²MySQLé›†ç¾¤
2. éƒ¨ç½²Redisé›†ç¾¤  
3. éƒ¨ç½²Kafkaé›†ç¾¤
4. éªŒè¯å­˜å‚¨æœåŠ¡

### é˜¶æ®µ3: åº”ç”¨æœåŠ¡éƒ¨ç½²
1. éƒ¨ç½²åç«¯æœåŠ¡
2. éƒ¨ç½²å‰ç«¯æœåŠ¡
3. é…ç½®è´Ÿè½½å‡è¡¡
4. å¥åº·æ£€æŸ¥éªŒè¯

### é˜¶æ®µ4: ç›‘æ§å‘Šè­¦é…ç½®
1. é…ç½®Prometheusç›‘æ§
2. é…ç½®Grafanaé¢æ¿
3. é…ç½®å‘Šè­¦è§„åˆ™
4. æµ‹è¯•å‘Šè­¦é€šçŸ¥

## è¿ç»´æœ€ä½³å®è·µ

### 1. ç›‘æ§æŒ‡æ ‡
- åº”ç”¨æ€§èƒ½æŒ‡æ ‡
- åŸºç¡€è®¾æ–½æŒ‡æ ‡
- ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§
- ç”¨æˆ·ä½“éªŒæŒ‡æ ‡

### 2. å¤‡ä»½ç­–ç•¥
- æ•°æ®åº“æ¯æ—¥å…¨é‡å¤‡ä»½
- é…ç½®æ–‡ä»¶ç‰ˆæœ¬æ§åˆ¶
- é•œåƒç‰ˆæœ¬ç®¡ç†
- ç¾éš¾æ¢å¤é¢„æ¡ˆ

### 3. å®‰å…¨ç»´æŠ¤
- å®šæœŸå®‰å…¨æ‰«æ
- æ¼æ´ä¿®å¤è·Ÿè¸ª
- è®¿é—®æ—¥å¿—å®¡è®¡
- æƒé™å®šæœŸreview

### 4. æ€§èƒ½ä¼˜åŒ–
- JVMå‚æ•°è°ƒä¼˜
- æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–
- ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- ç½‘ç»œæ€§èƒ½è°ƒä¼˜
```

## ğŸ¯ æ€»ç»“

æœ¬CI/CDä¸ç›‘æ§æ–¹æ¡ˆåŸºäºyudao-boot-miniæ¡†æ¶ï¼Œä¸ºæ™ºèƒ½é€šçŸ¥ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„DevOpsè§£å†³æ–¹æ¡ˆï¼š

### æ ¸å¿ƒç‰¹æ€§
1. **å…¨è‡ªåŠ¨åŒ–CI/CDæµæ°´çº¿** - ä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–
2. **å®Œå–„çš„ç›‘æ§ä½“ç³»** - è¦†ç›–åº”ç”¨ã€åŸºç¡€è®¾æ–½ã€ä¸šåŠ¡çš„å…¨æ–¹ä½ç›‘æ§
3. **æ™ºèƒ½å‘Šè­¦æœºåˆ¶** - å¤šçº§å‘Šè­¦ã€è‡ªåŠ¨æ¢å¤ã€æ™ºèƒ½é™å™ª
4. **é«˜å¯ç”¨æ¶æ„** - è“ç»¿éƒ¨ç½²ã€è‡ªåŠ¨æ‰©ç¼©å®¹ã€æ•…éšœè‡ªæ„ˆ
5. **å®‰å…¨é˜²æŠ¤ä½“ç³»** - é•œåƒæ‰«æã€è¿è¡Œæ—¶é˜²æŠ¤ã€è®¿é—®æ§åˆ¶

### æŠ€æœ¯äº®ç‚¹
- **å®¹å™¨åŒ–éƒ¨ç½²**: Dockerå¤šé˜¶æ®µæ„å»ºï¼Œä¼˜åŒ–é•œåƒå¤§å°
- **Kubernetesç¼–æ’**: HPA/VPAè‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œç¡®ä¿æœåŠ¡å¼¹æ€§
- **å¾®æœåŠ¡ç›‘æ§**: APMé“¾è·¯è¿½è¸ªï¼Œå…¨é“¾è·¯æ€§èƒ½åˆ†æ
- **æ—¥å¿—èšåˆ**: ELK Stacké›†ä¸­å¼æ—¥å¿—ç®¡ç†
- **è‡ªåŠ¨è¿ç»´**: æ™ºèƒ½å‘Šè­¦å¤„ç†ï¼Œå‡å°‘äººå·¥å¹²é¢„

### æ€§èƒ½ä¿éšœ
é€šè¿‡æœ¬æ–¹æ¡ˆå¯ä»¥å®ç°ï¼š
- **ç³»ç»Ÿå¯ç”¨æ€§**: 99.9%+
- **éƒ¨ç½²æ•ˆç‡**: ä»£ç åˆ°ç”Ÿäº§éƒ¨ç½² < 30åˆ†é’Ÿ
- **æ•…éšœæ¢å¤**: å¹³å‡æ•…éšœæ¢å¤æ—¶é—´ < 5åˆ†é’Ÿ
- **ç›‘æ§è¦†ç›–**: 100%ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§

è¯¥æ–¹æ¡ˆå……åˆ†è€ƒè™‘äº†é«˜å¹¶å‘æ¨é€åœºæ™¯çš„ç‰¹æ®Šéœ€æ±‚ï¼Œé€šè¿‡å®Œå–„çš„ç›‘æ§å’Œè‡ªåŠ¨åŒ–è¿ç»´ï¼Œç¡®ä¿æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿåœ¨å¤æ‚ä¸šåŠ¡åœºæ™¯ä¸‹çš„ç¨³å®šè¿è¡Œã€‚